[{"content":"Recording TBD\nSpeaker Charley Wu\nBio Charley Wu is a cognitive scientist who is interested in the specific shortcuts and cognitive algorithms that people use to make inference tractable. Using online and virtual reality experiments, He employs computational models to predict and understand human behavior. These models allow us to understand the strategies and approximations that allow people to do so much with so little. Originally trained in Philosophy at the University of British Columbia, He pivoted to cognitive science via a M.Sc. from the University of Vienna and a PhD in Psychology from Humboldt University of Berlin, while based at the Max Planck Institute for Human Development. Prior to joining the University of Tübingen, he was a postdoc at Harvard University working with Fiery Cushman and Sam Gershman.\nAbstract Humans are uniquely capable social learners. Our capacity to learn from others across short and long timescales is a driving force behind the success of our species. Yet there are seemingly maladaptive patterns of human social learning, characterized by both overreliance and underreliance on social information.\nRecent advances in animal research have incorporated rich visual and spatial dynamics to study social learning in ecological contexts, showing how simple mechanisms can give rise to intelligent group dynamics.However, similar techniques have yet to be translated into human research, which additionally requires integrating the sophistication of human individual and social learning mechanisms. Thus, it is still largely unknown how humans dynamically adapt social learning strategies to different environments and how group dynamics emerge under realistic conditions. Here, we use a collective foraging experiment in an immersive Minecraft environment to provide unique insights into how visual-spatial interactions give rise to adaptive, specialized, and selective social learning. Our analyses show how groups adapt to the demands of the environment through specialization of learning strategies rather than homogeneity and through the adaptive deployment of selective imitation rather than indiscriminate copying. We test these mechanisms using computational modeling, providing a deeper understanding of the cognitive mechanisms that dynamically influence social decision-making in ecological contexts. All results are compared against an asocial baseline, allowing us to specify specialization and selective attention as uniquely social phenomena, which provide the adaptive foundations of human social learning.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/wu231108/","summary":"Recording TBD\nSpeaker Charley Wu\nBio Charley Wu is a cognitive scientist who is interested in the specific shortcuts and cognitive algorithms that people use to make inference tractable. Using online and virtual reality experiments, He employs computational models to predict and understand human behavior. These models allow us to understand the strategies and approximations that allow people to do so much with so little. Originally trained in Philosophy at the University of British Columbia, He pivoted to cognitive science via a M.","title":"Charley Wu | Visual-spatial dynamics drive adaptive social learning in immersive environments"},{"content":"Recording https://www.bilibili.com/video/BV1Cy4y1w7Wx/\nSpeaker Taicheng Huang\nBio Taicheng Huang (黄泰诚) is a postdoc at Shanghai Mental Health Center, affiliated with Shanghai Jiao Tong University School of Medicine, under the supervision of Prof. Tifei Yuan (袁逖飞教授). He graduated from Beijing Normal University, and received doctoral training in cognitive neuroscience. Later, he came to Tsinghua University for formal training in cognitive science under the supervision of Prof. Jia Liu (刘嘉教授). Currently, he hopes to dive into psychiatry to integrate psychology, computational science and neuroscience to understand mental illnesses, especially addiction.\nAbstract This talk I will start with a paper entitled the hippocampus as a predictive map, which was published in Nature Neuroscience several years ago, to discuss the relations between cognitive map, predictive coding and world model. After rapidly going through the paper, one of my previous works will be introduced, which tried to build a reinforcement learning model to understand how humans accomplish stability inference in daily life, this work emphasizes the irreplaceability of cognitive map, or namely the structural knowledge for flexible behavior, in our daily activity. Later, I will summarize a general philosophical idea behind both works, then link this idea to modern artificial intelligence about the possibility of developing a human-like AI, further focus on some potential gaps that need to be filled in order to achieve the goal. Hopefully in this talk we can have a great discussion about some critical ideas, and I highly welcome audiences from different backgrounds to provide updated pioneer opinions.\n","permalink":"https://RLDMJC.github.io/posts/journaljam/huang231028/","summary":"Recording https://www.bilibili.com/video/BV1Cy4y1w7Wx/\nSpeaker Taicheng Huang\nBio Taicheng Huang (黄泰诚) is a postdoc at Shanghai Mental Health Center, affiliated with Shanghai Jiao Tong University School of Medicine, under the supervision of Prof. Tifei Yuan (袁逖飞教授). He graduated from Beijing Normal University, and received doctoral training in cognitive neuroscience. Later, he came to Tsinghua University for formal training in cognitive science under the supervision of Prof. Jia Liu (刘嘉教授). Currently, he hopes to dive into psychiatry to integrate psychology, computational science and neuroscience to understand mental illnesses, especially addiction.","title":"Taicheng Huang | Beyond the hippocampus as a predictive map"},{"content":"Recording https://www.bilibili.com/video/BV1QN4y1C77n/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Seongmin A. Park\nBio Seongmin A. Park is a researcher at the Institute of Cognitive Science Marc Jeannerod, CNRS (UMR5229), where he focuses on human learning and decision-making. He received his Ph.D. from the Korea Advanced Institute of Science and Technology and completed his postdoctoral training at CNRS with Dr. Jean-Claude Dreher and at UC Davis with Dr. Erie Boorm\nAbstract Generalizing past experiences to new situations is a hallmark of human intelligence, but it remains challenging for many AI systems. One proposed mechanism for achieving this behavioral flexibility is through the construction of an \u0026ldquo;internal model\u0026rdquo; or \u0026ldquo;cognitive map\u0026rdquo; - a structural knowledge representation that indicates the relationships between discrete entities learned from different events. However, we have yet to fully understand how the brain constructs low-dimensional representations from everyday experiences and leverages its cognitive map to promote generalization and flexible decision-making. In this talk, I will present research shedding light on these questions from human neuroimaging and neural network modeling. My findings suggest the brain organizes relationships between discrete entities into a graphical structure embedded in Euclidean space. Moreover, I will discuss how the geometry of the cognitive map interacts with changing task goals to facilitate flexible decision-making. Finally, I will provide evidence that the brain generalizes previously learned abstract knowledge structures to solve novel problems, akin to finding unexplored shortcuts during spatial navigation. By incorporating insights into the neural representation of cognitive maps into computational frameworks like reinforcement learning, my work indicates we can develop a deeper understanding of complex human cognition not fully accounted for by standard models. Uncovering the mechanisms underlying the brain\u0026rsquo;s remarkable behavioral flexibility has implications for advancing both cognitive science and artificial intelligence.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/park231020/","summary":"Recording https://www.bilibili.com/video/BV1QN4y1C77n/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Seongmin A. Park\nBio Seongmin A. Park is a researcher at the Institute of Cognitive Science Marc Jeannerod, CNRS (UMR5229), where he focuses on human learning and decision-making. He received his Ph.D. from the Korea Advanced Institute of Science and Technology and completed his postdoctoral training at CNRS with Dr. Jean-Claude Dreher and at UC Davis with Dr. Erie Boorm\nAbstract Generalizing past experiences to new situations is a hallmark of human intelligence, but it remains challenging for many AI systems.","title":" Seongmin A. Park | Structural abstraction and behavioral flexibility"},{"content":"Recording https://www.bilibili.com/video/BV1G34y1g7Q6/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Matt Nassar\nBio Matt Nassar is an Assistant Professor in the Department of Neuroscience at Brown University. He received his BA at Colgate University and his Doctorate from the University of Pennsylvania. He completed post-doctoral training at the University of Pennsylvania and Brown University before joining the faculty at Brown. His research examines how the brain prioritizes, segregates, and combines information collected in complex environments and how this process differs across individuals, pathologies, and over-healthy aging. For example, why and how do people prioritize sensory information arriving at certain times or locations? How does this prioritization differ across individuals and change across healthy aging How does the internal state of the brain affect ongoing cognition and sensory processing? What functions might these dynamic fluctuations serve in the real world?\nAbstract People flexibly adjust their use of information according to context. The same piece of information, for example, the unexpected outcome of an action, might be highly influential on future behavior in one situation \u0026ndash; but utterly ignored in another one. Bayesian models have provided insight into why people display this sort of behavior and even identified potential neural mechanisms that link to behavior in specific tasks and environments, but to date have fallen short of providing broader mechanistic insights that generalize across tasks or statistical environments. Here I\u0026rsquo;ll examine the possibility that such broader insights might be gained through careful consideration of task structure. I\u0026rsquo;ll show that we can think about a large number of sequential tasks as requiring the same inference problem \u0026ndash; that is to infer the latent states of the world and the parameters of those latent states \u0026ndash; with the primary distinctions within the class defined by transition structure. Then I\u0026rsquo;ll talk about how a neural network that updates latent states according to a known transition structure and learns \u0026ldquo;parameters\u0026rdquo; of the world for each latent state can explain adaptive learning behavior across environments and provide the first insights into neural correlates of adaptive learning across environments. This model generates internal signals that identify the need for latent state updating, which maps onto previous observations made in pupil dilations and P300 responses across different task environments. I will also discuss an experiment that we are currently setting up to test the idea that these signals might reflect a latent state update signal, with a focus on relationships to learning and perception. Finally, I discuss how deviations from normative structure learning might give rise to aberrant belief updating in mental illness.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/nassar231012/","summary":"Recording https://www.bilibili.com/video/BV1G34y1g7Q6/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Matt Nassar\nBio Matt Nassar is an Assistant Professor in the Department of Neuroscience at Brown University. He received his BA at Colgate University and his Doctorate from the University of Pennsylvania. He completed post-doctoral training at the University of Pennsylvania and Brown University before joining the faculty at Brown. His research examines how the brain prioritizes, segregates, and combines information collected in complex environments and how this process differs across individuals, pathologies, and over-healthy aging.","title":"Matt Nassar | Dynamic representations for behavioral flexibility"},{"content":"Recording https://www.bilibili.com/video/BV1P94y1a7Kf/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Mark Ho\nBio Mark Ho is an Assistant Professor in the Computer Science Department at Stevens Institute of Technology. Previously, he was a faculty fellow at NYU and a postdoc at Princeton and UC Berkeley. He received his Ph.D in Cognitive Science and M.S. in Computer Science from Brown University. His research combines approaches from cognitive science, social psychology, and computer science to study the computational principles underlying human problem solving and social cognition.\nAbstract One of the most striking features of human intelligence is our capacity to rapidly and flexibly plan. Planning enables us to solve myriad everyday problems\u0026mdash;e.g., planning how to complete a list of errands on a busy day\u0026mdash;but planning is also very computationally demanding. How do we effectively plan despite fundamental constraints on our time, memory, and attention? My talk will cover recent work investigating how the flexible construction of task representations facilitates efficient planning in humans. I will discuss value-guided construal, a general formal theory of how people form simplified, ad hoc representations in order to plan and act. By investigating the computational principles that underlie how people construe problems, this approach provides a new perspective on the dynamic interplay of attention, causal reasoning, and goal-directed behavior.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/ho231004/","summary":"Recording https://www.bilibili.com/video/BV1P94y1a7Kf/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Mark Ho\nBio Mark Ho is an Assistant Professor in the Computer Science Department at Stevens Institute of Technology. Previously, he was a faculty fellow at NYU and a postdoc at Princeton and UC Berkeley. He received his Ph.D in Cognitive Science and M.S. in Computer Science from Brown University. His research combines approaches from cognitive science, social psychology, and computer science to study the computational principles underlying human problem solving and social cognition.","title":"Mark Ho | Construction of mental representations in human planning"},{"content":"Recording https://www.bilibili.com/video/BV1Rh4y1a7iq/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Haoxue Fan\nBio Haoxue Fan is a fifth-year graduate student at Harvard working with Dr. Elizabeth Phelps. She is interested in how emotion interacts with decision-making under uncertainty, including cognitive processes such as exploration, information seeking, and planning. To answer these questions, she uses a combination of computational modeling, physiological measurements, and behavioral experiments. She is originally from Shanghai in China, and is always eager to know where is the best coffee and boba tea place in town :)\nAbstract Exploration is at the core of many real-life decisions, helping people gain information about the environment and make better choices in the long run. Although anxiety has been related to decreased physical exploration and avoidance behavior, past findings on the interaction between anxiety and exploration during decision-making under uncertainty were inconclusive. The current study provides a holistic picture of the anxiety-exploration relationship by focusing on latent factors of trait anxiety and different exploration strategies when facing volatility-induced uncertainty. Across two well-powered online studies (N = 984), we demonstrated that people used a hybrid of directed, random, and undirected exploration strategies, which were respectively sensitive to relative uncertainty, total uncertainty, and value difference. The somatic factor of trait anxiety, the propensity to experience physical symptoms of anxiety, was inversely correlated with directed exploration and undirected exploration, manifesting as being less likely to choose the uncertain option and reducing choice stochasticity regardless of uncertainty. Trait somatic anxiety was also related to underestimation of relative uncertainty, which could potentially account for its negative impact on directed exploration. Together, these results reveal the selective role of trait somatic anxiety and physiological arousal in modulating uncertainty-driven and value-driven exploration strategies. If time permits, I will also present a follow-up study where we examined the relationship between transitory physiological arousal - indexed by real-time pupil size - and exploration strategies. We showed that pupil size positively correlates with total uncertainty, suggesting a selective role of physiological arousal in driving uncertainty-driven random exploration. Additionally, we were able to decode subject-specific uncertainty estimates from pupillary data, which improves the predictive power of participants’ trial-by-trial choice variability.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/fan230922/","summary":"Recording https://www.bilibili.com/video/BV1Rh4y1a7iq/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Haoxue Fan\nBio Haoxue Fan is a fifth-year graduate student at Harvard working with Dr. Elizabeth Phelps. She is interested in how emotion interacts with decision-making under uncertainty, including cognitive processes such as exploration, information seeking, and planning. To answer these questions, she uses a combination of computational modeling, physiological measurements, and behavioral experiments. She is originally from Shanghai in China, and is always eager to know where is the best coffee and boba tea place in town :)","title":"Haoxue Fan | Trait somatic anxiety is associated with reduced directed exploration and underestimation of uncertainty"},{"content":"Recording https://www.bilibili.com/video/BV1sh4y1A7eu/\nSpeaker Stefano Palminteri\nBio I am a Research Director (equivalent of Full Professor) and head of the Human Reinforcement Learning team, which is part of the Laboratoire de Neurosciences Cognitives et Computationelles. My goal is understanding how humans learn to make decisions at the behavioral, computational and neural levels. I am mainly (but not only!) interested in situations when decisions are based on past experience (a.k.a. reinforcement learning). In the last few years I mainly worked on two computational hypotheses, \u0026ldquo;relative value\u0026rdquo; and \u0026ldquo;learning bias\u0026rdquo;, concerning human reinforcement learning. In addition to extending these two frameworks, new lines of research in my team investigate social learning , the experience/description gap and, more recently, the intersection between cognitive science and artificial intelligence. I also enjoy questioning the epistemological and methodological foundations of decision-making, neuroeconomics and cognitive science research.\nAbstract In the present talk I will review research performed by my and other laboratories that highlight the existence of reinforcement leaning biases. I will first start by briefly introducing the reinforcement learning framework and propose a taxonomy of biases within the framework itself. Then I will review direct empirical evidence supporting the existence of two learning biases: positivity bias and value-normalization at both the behavioral, neural and clinical level. Finally, I will present unpublished results of simulation studies that try to answer the question: what are these reinforcement learning biases good for?\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/palminteri230915/","summary":"Recording https://www.bilibili.com/video/BV1sh4y1A7eu/\nSpeaker Stefano Palminteri\nBio I am a Research Director (equivalent of Full Professor) and head of the Human Reinforcement Learning team, which is part of the Laboratoire de Neurosciences Cognitives et Computationelles. My goal is understanding how humans learn to make decisions at the behavioral, computational and neural levels. I am mainly (but not only!) interested in situations when decisions are based on past experience (a.k.a. reinforcement learning). In the last few years I mainly worked on two computational hypotheses, \u0026ldquo;relative value\u0026rdquo; and \u0026ldquo;learning bias\u0026rdquo;, concerning human reinforcement learning.","title":"Stefano Palminteri | Reinforcement learning biases that makes us smart"},{"content":"Recording https://www.bilibili.com/video/BV1Sj411C77e/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Zhaoyu Zuo\nBio Zhaoyu Zuo obtained a master\u0026rsquo;s degree in pattern recognition and intelligent systems from the University of Science and Technology of China and is now a research assistant at Shanghai Jiao Tong University. He is concerned with the nature of human intelligence and the mechanisms that lead to behavior and mental disorders. He uses brain-inspired models to study the cognitive computational mechanisms behind complex decisions, particularly the cooperative relationship between memory systems and reinforcement learning.\nAbstract Model-based (goal-directed) decision-making requires prudent evaluation of the ultimate consequences of multi-stage choices. Previous studies have suggested that such evaluation relies on the reward experience accumulated by the reinforcement learning process in the brain. However, the core component of model-based decision-making\u0026ndash;working memory (WM), also retains reward information, and it is still unclear whether WM contributes to the evaluation. The current study analyzes four two-stage decision experiments, which separately manipulate two WM-related variables (delay and load). We found that time delay interfered with evaluating the ultimate consequences, while increased task load reduced cognitive effort in the feedback process and the probability of selecting the optimal option. Notably, our proposed models that corporated the reward-retained mechanism of WM could replicate the behavioral effects of delay and load, whereas the classical hybrid reinforcement learning model could not. Furthermore, individual-level analysis revealed a close correlation between model parameters and WM scores. Together, these results provide a deeper understanding of how reinforcement learning and WM co-work in complex decision-making and facilitate analysis of impaired model-based decision-making in clinical populations.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/zuo230909/","summary":"Recording https://www.bilibili.com/video/BV1Sj411C77e/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Zhaoyu Zuo\nBio Zhaoyu Zuo obtained a master\u0026rsquo;s degree in pattern recognition and intelligent systems from the University of Science and Technology of China and is now a research assistant at Shanghai Jiao Tong University. He is concerned with the nature of human intelligence and the mechanisms that lead to behavior and mental disorders. He uses brain-inspired models to study the cognitive computational mechanisms behind complex decisions, particularly the cooperative relationship between memory systems and reinforcement learning.","title":"Zhaoyu Zuo | Working memory guides action valuation in model-based inference"},{"content":"Recording https://www.bilibili.com/video/BV1qm4y1u7JU/?spm_id_from=333.999.0.0\u0026amp;vd_source=1a260a61416c0a766c7c16e727b2f404\nSpeaker Shen Xu\nBio Shen Xu is a third-year Ph.D. student from the School of Psychological and Cognitive Sciences at Peking University. He studies Basic Psychology under the supervision of Professor Dr. Xiaolin Zhou, and he is mainly keen on millisecond tactile information integration and computational social cognition. For the former, Shen focuses on how different tactile information is integrated and its temporal dynamics in the human brain. For the latter, he focuses on the computational and neural mechanisms of advantageous and disadvantageous unfair decision-making in Parkinson\u0026rsquo;s patients.\nAbstract In recent years, the use of high-precision computational models in social science, cognitive science, and affective neuroscience has increased dramatically. These models can be matched with empirical data to facilitate quantitative studies of the cognitive neural mechanisms underlying behavior. Yet most psychological researchers lack hands-on experience with computational modeling. In this tutorial, I will talk about decision-making tasks in social learning, and data-fitting using hierarchical Bayesian reinforcement learning (hBRL) models within a more comprehensive computational modeling framework. We collected behavioral data from 82 participants using the classic four-armed bandit task and explored the cognitive effects associated with each model parameter. Our tutorial provides more detailed theoretical and practical guidance to help novices to implement their own computational models and avoid common pitfalls.\n","permalink":"https://RLDMJC.github.io/posts/tutorialtalk/xu230826/","summary":"Recording https://www.bilibili.com/video/BV1qm4y1u7JU/?spm_id_from=333.999.0.0\u0026amp;vd_source=1a260a61416c0a766c7c16e727b2f404\nSpeaker Shen Xu\nBio Shen Xu is a third-year Ph.D. student from the School of Psychological and Cognitive Sciences at Peking University. He studies Basic Psychology under the supervision of Professor Dr. Xiaolin Zhou, and he is mainly keen on millisecond tactile information integration and computational social cognition. For the former, Shen focuses on how different tactile information is integrated and its temporal dynamics in the human brain. For the latter, he focuses on the computational and neural mechanisms of advantageous and disadvantageous unfair decision-making in Parkinson\u0026rsquo;s patients.","title":"Shen Xu | Crash tutorials on fitting hierarchical Bayesian reinforcement learning models"},{"content":" Title Speaker Time (UTC+8) Type Language Zoom (password) Visual-spatial dynamics drive adaptive social learning in immersive environments Charley Wu (University of Tübingen) 2023/11/08 16:00 Research Recap English 87553097537（360255） RLDDM Miqing Guo 郭鸣谦 (Radboud University) 2023/11/18 21：00 Tutorial Talk Chinese TBD Explore-exploit Robert Wilson (University of Arizona) 2023/11/21 23:00 Research Recap English TBD TBD Weiji Ma 马伟基 (New York University) 2023/12/01 21：30 Research Recap English TBD Compositionality (Exact title TBD) Michael J Frank (Brown University) 2023/12/14 21：00 Research Recap English TBD TBD Toby Wise (KCL) 2024/2/29 21：00 Research Recap English TBD ","permalink":"https://RLDMJC.github.io/upcoming/","summary":" Title Speaker Time (UTC+8) Type Language Zoom (password) Visual-spatial dynamics drive adaptive social learning in immersive environments Charley Wu (University of Tübingen) 2023/11/08 16:00 Research Recap English 87553097537（360255） RLDDM Miqing Guo 郭鸣谦 (Radboud University) 2023/11/18 21：00 Tutorial Talk Chinese TBD Explore-exploit Robert Wilson (University of Arizona) 2023/11/21 23:00 Research Recap English TBD TBD Weiji Ma 马伟基 (New York University) 2023/12/01 21：30 Research Recap English TBD Compositionality (Exact title TBD) Michael J Frank (Brown University) 2023/12/14 21：00 Research Recap English TBD TBD Toby Wise (KCL) 2024/2/29 21：00 Research Recap English TBD ","title":"Upcoming Events"},{"content":"Recording https://www.bilibili.com/video/BV1au4y1R7kh/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Huadong Xiong\nBio I am a first-year Ph.D student in the CNS program, the department of psychology at the University of Arizona, directed by Dr. Robert Wilson. I build models to understand behaviors and I study how computation could be implemented in neural networks. Following the release of GPT-4, my research interest has partially shifted towards understanding the emergence of intelligence within large language models.\nAbstract The exploration-exploitation trade-off, balancing the acquisition of new information with the utilization of known resources, is a fundamental dilemma faced by all adaptive intelligence. Despite our understanding of models based on normative principles, the diverse explore-exploit behaviors of natural intelligence remain elusive. Here, using neural network behavioral modeling and state space analysis, we examined the diverse human exploration behaviors under a novel two-armed bandit task, designed to simulate real-world environmental volatility where exploration becomes essential. Examining behavior in the belief state space of this task, we characterized the disparities across artificial agents with decision boundaries. To extend this analysis to human data, a circumstance where choices are too sparse in the belief state space, we trained a recurrent neural network (RNN) model to predict humans’ choices given past observations. This RNN model outperforms all existing cognitive models. Probing the RNN’s decision boundaries, we found substantial individual differences that evade classical cognitive models. Additionally, our RNN revealed a model-based pattern employed by humans in response to higher environmental volatilities. Our work offers a promising approach for investigating diverse decision-making strategies in humans and animals.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/xiong230809/","summary":"Recording https://www.bilibili.com/video/BV1au4y1R7kh/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Huadong Xiong\nBio I am a first-year Ph.D student in the CNS program, the department of psychology at the University of Arizona, directed by Dr. Robert Wilson. I build models to understand behaviors and I study how computation could be implemented in neural networks. Following the release of GPT-4, my research interest has partially shifted towards understanding the emergence of intelligence within large language models.\nAbstract The exploration-exploitation trade-off, balancing the acquisition of new information with the utilization of known resources, is a fundamental dilemma faced by all adaptive intelligence.","title":"Huadong Xiong | Neural network modeling reveals diverse human exploration behaviors via state space analysis"},{"content":"MindRL is an academic commuity for researchers in the field of reinforcement learning. We co-founded this community with the hope of providing a platform for researchers to communicate and collaborate. We welcome peers from fields such as psychology, cognitive neuroscience, artificial intelligence, and other related disciplines such as mathematics, management and economics to build a more diverse and inclusive platform.\nWe have various activities such as:\nResearch Recap: researchers share their original research in RL. Journal Jam: community members interpret and report on journal articles in RL. Book Breakdown: community members read classic and cutting-edge books together. Tutorial Talks: community members share tutorials and practical experiences in RL. Tool Time: community members share the use and development of tools in RL. Who are we At the heart of the MindRL Hub Community lies the collective vision of four passionate friends, united by a common purpose to foster innovation, knowledge sharing, and collaboration in the fields of psychology, neuroscience and reinforcement learning.\nOur organizing committee is composed of Zeming Fang, Huaiyu Liu, Yanan Liu, and Hanbo Xie (in order of surname), each bringing a unique blend of expertise, experience, and cultural perspectives to the table. Hailing from diverse corners of the world, based on China, the UK, Canada, and the United States, we proudly represent a global network of minds dedicated to advancing the frontiers of reinforcement learning.\nWelcome to a community where geographical boundaries blur, and ideas flow freely across borders. How to join us If you want to join the community or participate in an event, please feel free to contact us via email (rldmjc2023@gmail.com).\n","permalink":"https://RLDMJC.github.io/about/","summary":"about","title":"What is MindRL"}]