[{"content":"Recording Speaker Christopher Summerfield\nBio Christopher Summerfield is a Fellow by special election and principal investigator at the Summerfield lab which conducts research into how humans make decisions. Chris Summerfield was trained in psychology and neuroscience at University College London, Columbia University (New York), and the École normale supérieure (Paris). He is a Professor of Cognitive Neuroscience in the Department of Experimental Psychology, where he heads a lab focused on understanding the computational mechanisms by which humans make decisions, and how these processes are implemented in the brain. His work, which involves a combination of computer simulations, behavioural testing, and functional brain imaging, is funded by a grant from the European Research Council, the Wellcome Trust, and the National Institute of Health. Recently, he accepted the position as the director at UK AI Safety Institute.\nAbstract Connectionist models have made a comeback as theories of brain function. Most advocates of this view have compared the structure of representations in biological and artificial neural networks, and argued that they are similar. However, neural networks learn with stereotyped dynamics which in some cases can be modelled exactly. In my talk, I will discuss projects in which we compare the learning dynamics in humans and deep networks during hierarchical category learning, task switching, dual task learning, and in-context (or “meta-“) learning. In each of these cases, we find striking commonalities between the dynamics of learning in deep networks, and those in our human participants.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/240628christopher-summerfield/","summary":"Recording Speaker Christopher Summerfield\nBio Christopher Summerfield is a Fellow by special election and principal investigator at the Summerfield lab which conducts research into how humans make decisions. Chris Summerfield was trained in psychology and neuroscience at University College London, Columbia University (New York), and the École normale supérieure (Paris). He is a Professor of Cognitive Neuroscience in the Department of Experimental Psychology, where he heads a lab focused on understanding the computational mechanisms by which humans make decisions, and how these processes are implemented in the brain.","title":"Christopher Summerfield | Comparing the learning dynamics of humans and deep networks"},{"content":"Recording https://www.bilibili.com/video/BV1rs421T7xX/?share_source=copy_web\nSpeaker Marc-Lluis Vives\nBio Marc-Lluis Vives is an Assistant Professor at Leiden University. He is interested in how the structure of mental representations predicts behavior in general and decision-making in particular.\nAbstract Decision-making is driven by how the situation is mentally constructed. Past research has successfully manipulated these decision frames by changing how a situation is described. It remains unknown, however, how decision frames are spontaneously constructed in the first place. In this talk, I\u0026rsquo;ll present evidence that semantic representations play a crucial role in frame construction, demonstrating that the structure of semantic spaces predicts decision-making. Furthermore, I\u0026rsquo;ll explore the reverse logic by showing how a key component of decision-making—uncertainty aversion—can predict the structure of semantic representations. Overall, I\u0026rsquo;ll discuss the often-overlooked link between semantic representations and decision-making processes.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/240614marc-lluis-vives/","summary":"Recording https://www.bilibili.com/video/BV1rs421T7xX/?share_source=copy_web\nSpeaker Marc-Lluis Vives\nBio Marc-Lluis Vives is an Assistant Professor at Leiden University. He is interested in how the structure of mental representations predicts behavior in general and decision-making in particular.\nAbstract Decision-making is driven by how the situation is mentally constructed. Past research has successfully manipulated these decision frames by changing how a situation is described. It remains unknown, however, how decision frames are spontaneously constructed in the first place.","title":"Marc-Lluis Vives | On the relationship between semantic representations and decision-making"},{"content":"Recording Speaker Arkady Konovalov\nBio I am an Associate Professor in the School of Psychology at the University of Birmingham. My research focuses on neuroeconomics and decision making in general, including models of the choice process, value-based learning, and social and strategic interactions, using methods of computational neuroscience such as response times modeling, fMRI, EEG, eye-tracking, and mouse-tracking.\nI received my PhD from the Ohio State University, where I worked with Ian Krajbich, PJ Healy, and John Kagel; I then got my postdoctoral training with Christian Ruff at the University of Zurich.\nAbstract Behavior in social contexts, including social learning, is often accompanied by neural activity in the brain network that includes the temporoparietal junction (TPJ), dorsomedial and dorsolateral prefrontal cortex (dmPFC and dlPFC), and precuneus. This network – typically referred to as the “social brain” – is often linked to information processing demands of life in social groups. While the precise nature of the computations in this network remains elusive, decision neuroscience has been trying to pin down the neural computations underlying strategic behavior and learning in the social brain network. I will discuss our recent work that focuses on such computations, including strategic decision-making and mentalization.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/240405konovalov/","summary":"Recording Speaker Arkady Konovalov\nBio I am an Associate Professor in the School of Psychology at the University of Birmingham. My research focuses on neuroeconomics and decision making in general, including models of the choice process, value-based learning, and social and strategic interactions, using methods of computational neuroscience such as response times modeling, fMRI, EEG, eye-tracking, and mouse-tracking.\nI received my PhD from the Ohio State University, where I worked with Ian Krajbich, PJ Healy, and John Kagel; I then got my postdoctoral training with Christian Ruff at the University of Zurich.","title":"Arkady Konovalov | Strategic Computations and Learning in the Social Brain"},{"content":"Recording Speaker Anne Collins\nBio I am currently an associate professor at UC Berkeley in the psychology department, with an affiliation in the Helen Wills Neuroscience institute. This semester, I\u0026rsquo;m also a visiting scholar at the University of Bordeaux, France. I did my undergrad at Ecole Polytechnique in France in Maths and engineering, and my PhD at Universite Pierre et Marie Curie, France. Then I was a postdoc at Brown university. I study human flexible learning and decision making using behavioral, computational and neuroscience methods.\nAbstract Reinforcement learning frameworks have contributed tremendously to our better understanding of learning processes in brain and behavior. However, this remarkable success obscures the reality of multiple underlying processes that support humans\u0026rsquo; unique flexibility and adaptability. In this talk, I will show that not accounting for such underlying processes in computational cognitive modeling weakens the generalizability and interpretability of findings, with important consequences in neuroscience, developmental, clinical research. I will present multiple approaches to disentangle the multiple processes that support flexible learning, including episodic and working memory processes. This works highlights the importance of studying learning as a multi-dimensional phenomenon that relies on multiple separable but inter-dependent computational mechanisms. Insights from how the brain implements learning is essential to informing generalizable, interpretable cognitive modeling.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/230922fan/","summary":"Recording Speaker Anne Collins\nBio I am currently an associate professor at UC Berkeley in the psychology department, with an affiliation in the Helen Wills Neuroscience institute. This semester, I\u0026rsquo;m also a visiting scholar at the University of Bordeaux, France. I did my undergrad at Ecole Polytechnique in France in Maths and engineering, and my PhD at Universite Pierre et Marie Curie, France. Then I was a postdoc at Brown university.","title":" Anne Collins | Deconstructing human reinforcement learning"},{"content":"Recording https://www.bilibili.com/video/BV12y421z7sj/?share_source=copy_web\u0026amp;vd_source=afe9405056278e6f25d039a72daab83b\nSpeaker Toby Wise\nBio Toby Wise is a Senior Research Fellow in the Department of Neuroimaging at the Institute of Psychiatry, Psychology \u0026amp; Neuroscience (IoPPN) at King\u0026rsquo;s College London.Toby started his academic career with a BSc in Psychology and MSc in Cognitive Neuroscience at the University of Sussex, before completing a PhD at the Institute of Psychiatry, Psychology and Neuroscience at King’s College London, where he focused on neuroimaging markers of depression and bipolar disorder. He then completed postdoctoral work at UCL and Caltech supported by a Sir Henry Wellcome postdoctoral fellowship from the Wellcome Trust. He returned to King\u0026rsquo;s College London in 2021 supported by a King\u0026rsquo;s Prize Fellowship, before starting his lab in 2023 supported by a Career Development Award from the Wellcome Trust.\nAbstract Estimating and responding to uncertainty appropriately is critical for learning, especially in environments that are changeable and difficult to predict. Simultaneously, perceptions of uncertainty are intimately linked to mental health problems such as anxiety disorders. In this talk, I will cover a set of studies that have used computational modelling to understand how humans learn about uncertainty, quantify individual-level estimates of uncertainty, and link these estimates to symptoms of common mental health problems. The results of these studies provide insights into how uncertainty guides learning across different contexts, and how the process of estimating uncertainty may go awry in mental health conditions.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/240229wise/","summary":"Recording https://www.bilibili.com/video/BV12y421z7sj/?share_source=copy_web\u0026amp;vd_source=afe9405056278e6f25d039a72daab83b\nSpeaker Toby Wise\nBio Toby Wise is a Senior Research Fellow in the Department of Neuroimaging at the Institute of Psychiatry, Psychology \u0026amp; Neuroscience (IoPPN) at King\u0026rsquo;s College London.Toby started his academic career with a BSc in Psychology and MSc in Cognitive Neuroscience at the University of Sussex, before completing a PhD at the Institute of Psychiatry, Psychology and Neuroscience at King’s College London, where he focused on neuroimaging markers of depression and bipolar disorder.","title":"Toby Wise | Learning about uncertainty: mechanisms and implications for mental health"},{"content":"Recording https://www.bilibili.com/video/BV14i4y1e7Lc/?vd_source=8b926cc5cb9e7d8fb85957e534d96e47\nSpeaker Michael J. Frank\nBio Michael J. Frank is Edgar L Marston Professor of Cognitive, Linguistic \u0026amp; Psychological Sciences at Brown University. He directs the Center for Computational Brain Science within the Carney Institute for Brain Science. He received his PhD in Neuroscience and Psychology in 2004 at the University of Colorado, following undergraduate and master\u0026rsquo;s degrees in electrical engineering. Frank’s work focuses primarily on theoretical models of frontostriatal circuits and their modulation by dopamine, especially their cognitive functions and implications for neurological and psychiatric disorders. The models are tested and refined with experiments across species, neural recording methods, and neuromodulation. Honors include the Troland Research Award from the National Academy of Sciences (2021), Kavli Fellow (2016), the Cognitive Neuroscience Society Young Investigator Award (2011), and the Janet T Spence Award for early career transformative contributions (Association for Psychological Science, 2010). Dr Frank is a senior editor for eLife.\nAbstract Humans are remarkably adept at generalizing knowledge between experiences in a way that can be difficult for computers. Previous computational models and data suggest that rather than learning about each individual context, humans build latent abstract structures and learn to link these structures to arbitrary contexts, facilitating generalization, but with a cost in efficiency of initial learning. In these models, task structures that are more popular across contexts are likely to be reused in new contexts. Neural signatures of such structure learning are predictive across individuals of the ability to transfer knowledge to new situations. However, these models predict that structures are either re-used as a whole or created from scratch, prohibiting the ability to generalize constituent parts of learned structures. This contrasts with ecological settings, where task structures can be decomposed into constituent parts and reused in a compositional fashion. Moreover in many situations people can transfer structures that they have learned to entirely new situations, by analogy, even when surface aspects of the transition and reward functions change. I will present novel computational models across levels (from neural networks to bayesian formulations) that address how agents and humans can learn and generalize such abstract and compositional structure.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/231214frank/","summary":"Recording https://www.bilibili.com/video/BV14i4y1e7Lc/?vd_source=8b926cc5cb9e7d8fb85957e534d96e47\nSpeaker Michael J. Frank\nBio Michael J. Frank is Edgar L Marston Professor of Cognitive, Linguistic \u0026amp; Psychological Sciences at Brown University. He directs the Center for Computational Brain Science within the Carney Institute for Brain Science. He received his PhD in Neuroscience and Psychology in 2004 at the University of Colorado, following undergraduate and master\u0026rsquo;s degrees in electrical engineering. Frank’s work focuses primarily on theoretical models of frontostriatal circuits and their modulation by dopamine, especially their cognitive functions and implications for neurological and psychiatric disorders.","title":"Michael J. Frank | Clustering and generalization of abstract structures in reinforcement learning"},{"content":"Recording https://www.bilibili.com/video/BV1vg4y1f7ey/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Robert C. Wilson\nBio Bob Wilson is an Associate Professor of Psychology and Director of the Cognitive Science Program at the University of Arizona. Bob is interested in the computational neuroscience of decision-making, studying all kinds of choices from simple perceptual decisions to judgments about phishing emails. Outside of the lab, Bob enjoys raising chickens and learning the piano.\nAbstract Many decisions involve a trade-off between exploring unknown options for information and exploiting known options for a more certain payoff. In this talk, I will present evidence that people use two strategies to solve these explore-exploit dilemmas: directed exploration, driven by information, and random exploitation, driven by noise. These two strategies appear to rely on dissociable cognitive and neural processes, but I will show that they can arise from a single model based on mental simulation. This model accounts for the effects of uncertainty, time horizon, and the informativeness of feedback on directed and random exploitation as well as more recent findings suggesting that random exploitation is truly random. I will end with a discussion of our future work on real-world decisions.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/231205wilson/","summary":"Recording https://www.bilibili.com/video/BV1vg4y1f7ey/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Robert C. Wilson\nBio Bob Wilson is an Associate Professor of Psychology and Director of the Cognitive Science Program at the University of Arizona. Bob is interested in the computational neuroscience of decision-making, studying all kinds of choices from simple perceptual decisions to judgments about phishing emails. Outside of the lab, Bob enjoys raising chickens and learning the piano.\nAbstract Many decisions involve a trade-off between exploring unknown options for information and exploiting known options for a more certain payoff.","title":"Robert C. Wilson | Information, randomization, and simulation in exploration and exploitation"},{"content":"Recording https://www.bilibili.com/video/BV1ye411d7Ty/?spm_id_from=333.999.0.0\u0026amp;vd_source=8b926cc5cb9e7d8fb85957e534d96e47\nSpeaker Weiji Ma\nBio Wei Ji Ma is Professor of Neural Science and Psychology at New York University. He received his Ph.D. in Theoretical Physics from the University of Groningen, the Netherlands, in 2001. He switched to computational neuroscience and computational cognitive science, doing postdocs at Caltech and the University of Rochester. He was Assistant Professor of Neuroscience at Baylor College of Medicine from 2008 to 2013 before he joined New York University. His lab uses behavioral experiments, computational models, and (through collaboration) neural measures to investigate how people make perceptual and cognitive decisions. Ma has worked on topics in visual decision-making, neural coding and computation, multisensory perception, working memory, metacognition, complex planning, procrastination, and mindsets. He is the lead author of the textbook Bayesian models of Perception and Action, published by MIT Press in 2023.\nMa is the Program Director of the NIH-funded Training Program in Computational Neuroscience at NYU. He founded the \u0026ldquo;Growing up in Science\u0026rdquo; mentorship series, in which scientists tell their life stories with an emphasis on doubts, struggles, and failures. He is also a founding member of the Scientist Action and Advocacy Network, which provides pro-bono science to social and environmental non-profit organizations. He co-founded the Rural China Education Foundation, which supports community-based elementary education in rural China. In 2021, Ma received the Elman Prize for Scientific Achievement and Community Building from the Cognitive Science Society, and in 2023, he received the Impact Goals Award from the Center for Advancing Research Impact in Society.\nAbstract As DeepMind has revolutionized the AI of planning in combinatorially large problems, our lack of understanding of how humans plan in such situations has come into stark focus. The cognitive science of chess, once promising, is now virtually extinct. Planning tasks that are nowadays widely used in the field don’t require much thinking ahead. I will show that it is possible to study human complex planning in tasks of intermediate complexity while maintaining experimental tractability and computational modelability. I will describe experiments on a game that we call four-in-a-row \u0026ndash; a variant of tic-tac-toe or Go Moku. Inspired by best-first search, we built a heuristic computational model of human play in this game and fitted it to move-level data. The model predicts moves in unseen positions, decisions in unseen tasks, eye fixation patterns, mouse movements, and response times. Moreover, the model allows us to computationally characterize the effects of expertise and time pressure. Linking back to the chess literature, I will discuss how experts differ from novices in remembering game positions and move sequences. I will describe parallel results from a very large online data set, connections to development, and ongoing work on the neural basis of complex planning. Finally, I will comment on some broader themes: resisting reductionism, the use of games to study cognition, and comparisons to other species.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/231201ma/","summary":"Recording https://www.bilibili.com/video/BV1ye411d7Ty/?spm_id_from=333.999.0.0\u0026amp;vd_source=8b926cc5cb9e7d8fb85957e534d96e47\nSpeaker Weiji Ma\nBio Wei Ji Ma is Professor of Neural Science and Psychology at New York University. He received his Ph.D. in Theoretical Physics from the University of Groningen, the Netherlands, in 2001. He switched to computational neuroscience and computational cognitive science, doing postdocs at Caltech and the University of Rochester. He was Assistant Professor of Neuroscience at Baylor College of Medicine from 2008 to 2013 before he joined New York University.","title":"Weiji Ma | The cognitive science of complex planning"},{"content":"Recording https://www.bilibili.com/video/BV1ZM411S7d7/\nSpeaker Charley Wu\nBio Charley Wu is a cognitive scientist who is interested in the specific shortcuts and cognitive algorithms that people use to make inference tractable. Using online and virtual reality experiments, He employs computational models to predict and understand human behavior. These models allow us to understand the strategies and approximations that allow people to do so much with so little. Originally trained in Philosophy at the University of British Columbia, He pivoted to cognitive science via a M.Sc. from the University of Vienna and a PhD in Psychology from Humboldt University of Berlin, while based at the Max Planck Institute for Human Development. Prior to joining the University of Tübingen, he was a postdoc at Harvard University working with Fiery Cushman and Sam Gershman.\nAbstract Humans are uniquely capable social learners. Our capacity to learn from others across short and long timescales is a driving force behind the success of our species. Yet there are seemingly maladaptive patterns of human social learning, characterized by both overreliance and underreliance on social information.\nRecent advances in animal research have incorporated rich visual and spatial dynamics to study social learning in ecological contexts, showing how simple mechanisms can give rise to intelligent group dynamics.However, similar techniques have yet to be translated into human research, which additionally requires integrating the sophistication of human individual and social learning mechanisms. Thus, it is still largely unknown how humans dynamically adapt social learning strategies to different environments and how group dynamics emerge under realistic conditions. Here, we use a collective foraging experiment in an immersive Minecraft environment to provide unique insights into how visual-spatial interactions give rise to adaptive, specialized, and selective social learning. Our analyses show how groups adapt to the demands of the environment through specialization of learning strategies rather than homogeneity and through the adaptive deployment of selective imitation rather than indiscriminate copying. We test these mechanisms using computational modeling, providing a deeper understanding of the cognitive mechanisms that dynamically influence social decision-making in ecological contexts. All results are compared against an asocial baseline, allowing us to specify specialization and selective attention as uniquely social phenomena, which provide the adaptive foundations of human social learning.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/231108wu/","summary":"Recording https://www.bilibili.com/video/BV1ZM411S7d7/\nSpeaker Charley Wu\nBio Charley Wu is a cognitive scientist who is interested in the specific shortcuts and cognitive algorithms that people use to make inference tractable. Using online and virtual reality experiments, He employs computational models to predict and understand human behavior. These models allow us to understand the strategies and approximations that allow people to do so much with so little. Originally trained in Philosophy at the University of British Columbia, He pivoted to cognitive science via a M.","title":"Charley Wu | Visual-spatial dynamics drive adaptive social learning in immersive environments"},{"content":"Recording https://www.bilibili.com/video/BV1Cy4y1w7Wx/\nSpeaker Taicheng Huang\nBio Taicheng Huang (黄泰诚) is a postdoc at Shanghai Mental Health Center, affiliated with Shanghai Jiao Tong University School of Medicine, under the supervision of Prof. Tifei Yuan (袁逖飞教授). He graduated from Beijing Normal University, and received doctoral training in cognitive neuroscience. Later, he came to Tsinghua University for formal training in cognitive science under the supervision of Prof. Jia Liu (刘嘉教授). Currently, he hopes to dive into psychiatry to integrate psychology, computational science and neuroscience to understand mental illnesses, especially addiction.\nAbstract This talk I will start with a paper entitled the hippocampus as a predictive map, which was published in Nature Neuroscience several years ago, to discuss the relations between cognitive map, predictive coding and world model. After rapidly going through the paper, one of my previous works will be introduced, which tried to build a reinforcement learning model to understand how humans accomplish stability inference in daily life, this work emphasizes the irreplaceability of cognitive map, or namely the structural knowledge for flexible behavior, in our daily activity. Later, I will summarize a general philosophical idea behind both works, then link this idea to modern artificial intelligence about the possibility of developing a human-like AI, further focus on some potential gaps that need to be filled in order to achieve the goal. Hopefully in this talk we can have a great discussion about some critical ideas, and I highly welcome audiences from different backgrounds to provide updated pioneer opinions.\n","permalink":"https://RLDMJC.github.io/posts/journaljam/huang231028/","summary":"Recording https://www.bilibili.com/video/BV1Cy4y1w7Wx/\nSpeaker Taicheng Huang\nBio Taicheng Huang (黄泰诚) is a postdoc at Shanghai Mental Health Center, affiliated with Shanghai Jiao Tong University School of Medicine, under the supervision of Prof. Tifei Yuan (袁逖飞教授). He graduated from Beijing Normal University, and received doctoral training in cognitive neuroscience. Later, he came to Tsinghua University for formal training in cognitive science under the supervision of Prof. Jia Liu (刘嘉教授). Currently, he hopes to dive into psychiatry to integrate psychology, computational science and neuroscience to understand mental illnesses, especially addiction.","title":"Taicheng Huang | Beyond the hippocampus as a predictive map"},{"content":"Recording https://www.bilibili.com/video/BV1QN4y1C77n/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Seongmin A. Park\nBio Seongmin A. Park is a researcher at the Institute of Cognitive Science Marc Jeannerod, CNRS (UMR5229), where he focuses on human learning and decision-making. He received his Ph.D. from the Korea Advanced Institute of Science and Technology and completed his postdoctoral training at CNRS with Dr. Jean-Claude Dreher and at UC Davis with Dr. Erie Boorm\nAbstract Generalizing past experiences to new situations is a hallmark of human intelligence, but it remains challenging for many AI systems. One proposed mechanism for achieving this behavioral flexibility is through the construction of an \u0026ldquo;internal model\u0026rdquo; or \u0026ldquo;cognitive map\u0026rdquo; - a structural knowledge representation that indicates the relationships between discrete entities learned from different events. However, we have yet to fully understand how the brain constructs low-dimensional representations from everyday experiences and leverages its cognitive map to promote generalization and flexible decision-making. In this talk, I will present research shedding light on these questions from human neuroimaging and neural network modeling. My findings suggest the brain organizes relationships between discrete entities into a graphical structure embedded in Euclidean space. Moreover, I will discuss how the geometry of the cognitive map interacts with changing task goals to facilitate flexible decision-making. Finally, I will provide evidence that the brain generalizes previously learned abstract knowledge structures to solve novel problems, akin to finding unexplored shortcuts during spatial navigation. By incorporating insights into the neural representation of cognitive maps into computational frameworks like reinforcement learning, my work indicates we can develop a deeper understanding of complex human cognition not fully accounted for by standard models. Uncovering the mechanisms underlying the brain\u0026rsquo;s remarkable behavioral flexibility has implications for advancing both cognitive science and artificial intelligence.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/231020park/","summary":"Recording https://www.bilibili.com/video/BV1QN4y1C77n/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Seongmin A. Park\nBio Seongmin A. Park is a researcher at the Institute of Cognitive Science Marc Jeannerod, CNRS (UMR5229), where he focuses on human learning and decision-making. He received his Ph.D. from the Korea Advanced Institute of Science and Technology and completed his postdoctoral training at CNRS with Dr. Jean-Claude Dreher and at UC Davis with Dr. Erie Boorm\nAbstract Generalizing past experiences to new situations is a hallmark of human intelligence, but it remains challenging for many AI systems.","title":" Seongmin A. Park | Structural abstraction and behavioral flexibility"},{"content":"Recording https://www.bilibili.com/video/BV1G34y1g7Q6/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Matt Nassar\nBio Matt Nassar is an Assistant Professor in the Department of Neuroscience at Brown University. He received his BA at Colgate University and his Doctorate from the University of Pennsylvania. He completed post-doctoral training at the University of Pennsylvania and Brown University before joining the faculty at Brown. His research examines how the brain prioritizes, segregates, and combines information collected in complex environments and how this process differs across individuals, pathologies, and over-healthy aging. For example, why and how do people prioritize sensory information arriving at certain times or locations? How does this prioritization differ across individuals and change across healthy aging How does the internal state of the brain affect ongoing cognition and sensory processing? What functions might these dynamic fluctuations serve in the real world?\nAbstract People flexibly adjust their use of information according to context. The same piece of information, for example, the unexpected outcome of an action, might be highly influential on future behavior in one situation \u0026ndash; but utterly ignored in another one. Bayesian models have provided insight into why people display this sort of behavior and even identified potential neural mechanisms that link to behavior in specific tasks and environments, but to date have fallen short of providing broader mechanistic insights that generalize across tasks or statistical environments. Here I\u0026rsquo;ll examine the possibility that such broader insights might be gained through careful consideration of task structure. I\u0026rsquo;ll show that we can think about a large number of sequential tasks as requiring the same inference problem \u0026ndash; that is to infer the latent states of the world and the parameters of those latent states \u0026ndash; with the primary distinctions within the class defined by transition structure. Then I\u0026rsquo;ll talk about how a neural network that updates latent states according to a known transition structure and learns \u0026ldquo;parameters\u0026rdquo; of the world for each latent state can explain adaptive learning behavior across environments and provide the first insights into neural correlates of adaptive learning across environments. This model generates internal signals that identify the need for latent state updating, which maps onto previous observations made in pupil dilations and P300 responses across different task environments. I will also discuss an experiment that we are currently setting up to test the idea that these signals might reflect a latent state update signal, with a focus on relationships to learning and perception. Finally, I discuss how deviations from normative structure learning might give rise to aberrant belief updating in mental illness.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/231012nassar/","summary":"Recording https://www.bilibili.com/video/BV1G34y1g7Q6/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Matt Nassar\nBio Matt Nassar is an Assistant Professor in the Department of Neuroscience at Brown University. He received his BA at Colgate University and his Doctorate from the University of Pennsylvania. He completed post-doctoral training at the University of Pennsylvania and Brown University before joining the faculty at Brown. His research examines how the brain prioritizes, segregates, and combines information collected in complex environments and how this process differs across individuals, pathologies, and over-healthy aging.","title":"Matt Nassar | Dynamic representations for behavioral flexibility"},{"content":"Recording https://www.bilibili.com/video/BV1P94y1a7Kf/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Mark Ho\nBio Mark Ho is an Assistant Professor in the Computer Science Department at Stevens Institute of Technology. Previously, he was a faculty fellow at NYU and a postdoc at Princeton and UC Berkeley. He received his Ph.D in Cognitive Science and M.S. in Computer Science from Brown University. His research combines approaches from cognitive science, social psychology, and computer science to study the computational principles underlying human problem solving and social cognition.\nAbstract One of the most striking features of human intelligence is our capacity to rapidly and flexibly plan. Planning enables us to solve myriad everyday problems\u0026mdash;e.g., planning how to complete a list of errands on a busy day\u0026mdash;but planning is also very computationally demanding. How do we effectively plan despite fundamental constraints on our time, memory, and attention? My talk will cover recent work investigating how the flexible construction of task representations facilitates efficient planning in humans. I will discuss value-guided construal, a general formal theory of how people form simplified, ad hoc representations in order to plan and act. By investigating the computational principles that underlie how people construe problems, this approach provides a new perspective on the dynamic interplay of attention, causal reasoning, and goal-directed behavior.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/231004ho/","summary":"Recording https://www.bilibili.com/video/BV1P94y1a7Kf/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Mark Ho\nBio Mark Ho is an Assistant Professor in the Computer Science Department at Stevens Institute of Technology. Previously, he was a faculty fellow at NYU and a postdoc at Princeton and UC Berkeley. He received his Ph.D in Cognitive Science and M.S. in Computer Science from Brown University. His research combines approaches from cognitive science, social psychology, and computer science to study the computational principles underlying human problem solving and social cognition.","title":"Mark Ho | Construction of mental representations in human planning"},{"content":"Recording https://www.bilibili.com/video/BV1Rh4y1a7iq/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Haoxue Fan\nBio Haoxue Fan is a fifth-year graduate student at Harvard working with Dr. Elizabeth Phelps. She is interested in how emotion interacts with decision-making under uncertainty, including cognitive processes such as exploration, information seeking, and planning. To answer these questions, she uses a combination of computational modeling, physiological measurements, and behavioral experiments. She is originally from Shanghai in China, and is always eager to know where is the best coffee and boba tea place in town :)\nAbstract Exploration is at the core of many real-life decisions, helping people gain information about the environment and make better choices in the long run. Although anxiety has been related to decreased physical exploration and avoidance behavior, past findings on the interaction between anxiety and exploration during decision-making under uncertainty were inconclusive. The current study provides a holistic picture of the anxiety-exploration relationship by focusing on latent factors of trait anxiety and different exploration strategies when facing volatility-induced uncertainty. Across two well-powered online studies (N = 984), we demonstrated that people used a hybrid of directed, random, and undirected exploration strategies, which were respectively sensitive to relative uncertainty, total uncertainty, and value difference. The somatic factor of trait anxiety, the propensity to experience physical symptoms of anxiety, was inversely correlated with directed exploration and undirected exploration, manifesting as being less likely to choose the uncertain option and reducing choice stochasticity regardless of uncertainty. Trait somatic anxiety was also related to underestimation of relative uncertainty, which could potentially account for its negative impact on directed exploration. Together, these results reveal the selective role of trait somatic anxiety and physiological arousal in modulating uncertainty-driven and value-driven exploration strategies. If time permits, I will also present a follow-up study where we examined the relationship between transitory physiological arousal - indexed by real-time pupil size - and exploration strategies. We showed that pupil size positively correlates with total uncertainty, suggesting a selective role of physiological arousal in driving uncertainty-driven random exploration. Additionally, we were able to decode subject-specific uncertainty estimates from pupillary data, which improves the predictive power of participants’ trial-by-trial choice variability.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/240329collins/","summary":"Recording https://www.bilibili.com/video/BV1Rh4y1a7iq/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Haoxue Fan\nBio Haoxue Fan is a fifth-year graduate student at Harvard working with Dr. Elizabeth Phelps. She is interested in how emotion interacts with decision-making under uncertainty, including cognitive processes such as exploration, information seeking, and planning. To answer these questions, she uses a combination of computational modeling, physiological measurements, and behavioral experiments. She is originally from Shanghai in China, and is always eager to know where is the best coffee and boba tea place in town :)","title":"Haoxue Fan | Trait somatic anxiety is associated with reduced directed exploration and underestimation of uncertainty"},{"content":"Recording https://www.bilibili.com/video/BV1sh4y1A7eu/\nSpeaker Stefano Palminteri\nBio I am a Research Director (equivalent of Full Professor) and head of the Human Reinforcement Learning team, which is part of the Laboratoire de Neurosciences Cognitives et Computationelles. My goal is understanding how humans learn to make decisions at the behavioral, computational and neural levels. I am mainly (but not only!) interested in situations when decisions are based on past experience (a.k.a. reinforcement learning). In the last few years I mainly worked on two computational hypotheses, \u0026ldquo;relative value\u0026rdquo; and \u0026ldquo;learning bias\u0026rdquo;, concerning human reinforcement learning. In addition to extending these two frameworks, new lines of research in my team investigate social learning , the experience/description gap and, more recently, the intersection between cognitive science and artificial intelligence. I also enjoy questioning the epistemological and methodological foundations of decision-making, neuroeconomics and cognitive science research.\nAbstract In the present talk I will review research performed by my and other laboratories that highlight the existence of reinforcement leaning biases. I will first start by briefly introducing the reinforcement learning framework and propose a taxonomy of biases within the framework itself. Then I will review direct empirical evidence supporting the existence of two learning biases: positivity bias and value-normalization at both the behavioral, neural and clinical level. Finally, I will present unpublished results of simulation studies that try to answer the question: what are these reinforcement learning biases good for?\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/230915palminteri/","summary":"Recording https://www.bilibili.com/video/BV1sh4y1A7eu/\nSpeaker Stefano Palminteri\nBio I am a Research Director (equivalent of Full Professor) and head of the Human Reinforcement Learning team, which is part of the Laboratoire de Neurosciences Cognitives et Computationelles. My goal is understanding how humans learn to make decisions at the behavioral, computational and neural levels. I am mainly (but not only!) interested in situations when decisions are based on past experience (a.k.a. reinforcement learning). In the last few years I mainly worked on two computational hypotheses, \u0026ldquo;relative value\u0026rdquo; and \u0026ldquo;learning bias\u0026rdquo;, concerning human reinforcement learning.","title":"Stefano Palminteri | Reinforcement learning biases that makes us smart"},{"content":"Recording https://www.bilibili.com/video/BV1Sj411C77e/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Zhaoyu Zuo\nBio Zhaoyu Zuo obtained a master\u0026rsquo;s degree in pattern recognition and intelligent systems from the University of Science and Technology of China and is now a research assistant at Shanghai Jiao Tong University. He is concerned with the nature of human intelligence and the mechanisms that lead to behavior and mental disorders. He uses brain-inspired models to study the cognitive computational mechanisms behind complex decisions, particularly the cooperative relationship between memory systems and reinforcement learning.\nAbstract Model-based (goal-directed) decision-making requires prudent evaluation of the ultimate consequences of multi-stage choices. Previous studies have suggested that such evaluation relies on the reward experience accumulated by the reinforcement learning process in the brain. However, the core component of model-based decision-making\u0026ndash;working memory (WM), also retains reward information, and it is still unclear whether WM contributes to the evaluation. The current study analyzes four two-stage decision experiments, which separately manipulate two WM-related variables (delay and load). We found that time delay interfered with evaluating the ultimate consequences, while increased task load reduced cognitive effort in the feedback process and the probability of selecting the optimal option. Notably, our proposed models that corporated the reward-retained mechanism of WM could replicate the behavioral effects of delay and load, whereas the classical hybrid reinforcement learning model could not. Furthermore, individual-level analysis revealed a close correlation between model parameters and WM scores. Together, these results provide a deeper understanding of how reinforcement learning and WM co-work in complex decision-making and facilitate analysis of impaired model-based decision-making in clinical populations.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/230909zuo/","summary":"Recording https://www.bilibili.com/video/BV1Sj411C77e/?vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Zhaoyu Zuo\nBio Zhaoyu Zuo obtained a master\u0026rsquo;s degree in pattern recognition and intelligent systems from the University of Science and Technology of China and is now a research assistant at Shanghai Jiao Tong University. He is concerned with the nature of human intelligence and the mechanisms that lead to behavior and mental disorders. He uses brain-inspired models to study the cognitive computational mechanisms behind complex decisions, particularly the cooperative relationship between memory systems and reinforcement learning.","title":"Zhaoyu Zuo | Working memory guides action valuation in model-based inference"},{"content":"Recording https://www.bilibili.com/video/BV1qm4y1u7JU/?spm_id_from=333.999.0.0\u0026amp;vd_source=1a260a61416c0a766c7c16e727b2f404\nSpeaker Shen Xu\nBio Shen Xu is a third-year Ph.D. student from the School of Psychological and Cognitive Sciences at Peking University. He studies Basic Psychology under the supervision of Professor Dr. Xiaolin Zhou, and he is mainly keen on millisecond tactile information integration and computational social cognition. For the former, Shen focuses on how different tactile information is integrated and its temporal dynamics in the human brain. For the latter, he focuses on the computational and neural mechanisms of advantageous and disadvantageous unfair decision-making in Parkinson\u0026rsquo;s patients.\nAbstract In recent years, the use of high-precision computational models in social science, cognitive science, and affective neuroscience has increased dramatically. These models can be matched with empirical data to facilitate quantitative studies of the cognitive neural mechanisms underlying behavior. Yet most psychological researchers lack hands-on experience with computational modeling. In this tutorial, I will talk about decision-making tasks in social learning, and data-fitting using hierarchical Bayesian reinforcement learning (hBRL) models within a more comprehensive computational modeling framework. We collected behavioral data from 82 participants using the classic four-armed bandit task and explored the cognitive effects associated with each model parameter. Our tutorial provides more detailed theoretical and practical guidance to help novices to implement their own computational models and avoid common pitfalls.\n","permalink":"https://RLDMJC.github.io/posts/tutorialtalk/xu230826/","summary":"Recording https://www.bilibili.com/video/BV1qm4y1u7JU/?spm_id_from=333.999.0.0\u0026amp;vd_source=1a260a61416c0a766c7c16e727b2f404\nSpeaker Shen Xu\nBio Shen Xu is a third-year Ph.D. student from the School of Psychological and Cognitive Sciences at Peking University. He studies Basic Psychology under the supervision of Professor Dr. Xiaolin Zhou, and he is mainly keen on millisecond tactile information integration and computational social cognition. For the former, Shen focuses on how different tactile information is integrated and its temporal dynamics in the human brain. For the latter, he focuses on the computational and neural mechanisms of advantageous and disadvantageous unfair decision-making in Parkinson\u0026rsquo;s patients.","title":"Shen Xu | Crash tutorials on fitting hierarchical Bayesian reinforcement learning models"},{"content":" Title Speaker Time (UTC+8) Type Language Zoom (password) Comparing the learning dynamics of humans and deep networks Christopher Summerfield 2024-6-28, 4pm-5pm Research Recap English 899 942 44449 (466406) ","permalink":"https://RLDMJC.github.io/upcoming/","summary":" Title Speaker Time (UTC+8) Type Language Zoom (password) Comparing the learning dynamics of humans and deep networks Christopher Summerfield 2024-6-28, 4pm-5pm Research Recap English 899 942 44449 (466406) ","title":"Upcoming Events"},{"content":"Recording https://www.bilibili.com/video/BV1au4y1R7kh/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Huadong Xiong\nBio I am a first-year Ph.D student in the CNS program, the department of psychology at the University of Arizona, directed by Dr. Robert Wilson. I build models to understand behaviors and I study how computation could be implemented in neural networks. Following the release of GPT-4, my research interest has partially shifted towards understanding the emergence of intelligence within large language models.\nAbstract The exploration-exploitation trade-off, balancing the acquisition of new information with the utilization of known resources, is a fundamental dilemma faced by all adaptive intelligence. Despite our understanding of models based on normative principles, the diverse explore-exploit behaviors of natural intelligence remain elusive. Here, using neural network behavioral modeling and state space analysis, we examined the diverse human exploration behaviors under a novel two-armed bandit task, designed to simulate real-world environmental volatility where exploration becomes essential. Examining behavior in the belief state space of this task, we characterized the disparities across artificial agents with decision boundaries. To extend this analysis to human data, a circumstance where choices are too sparse in the belief state space, we trained a recurrent neural network (RNN) model to predict humans’ choices given past observations. This RNN model outperforms all existing cognitive models. Probing the RNN’s decision boundaries, we found substantial individual differences that evade classical cognitive models. Additionally, our RNN revealed a model-based pattern employed by humans in response to higher environmental volatilities. Our work offers a promising approach for investigating diverse decision-making strategies in humans and animals.\n","permalink":"https://RLDMJC.github.io/posts/researchrecap/230809xiong/","summary":"Recording https://www.bilibili.com/video/BV1au4y1R7kh/?spm_id_from=333.999.0.0\u0026amp;vd_source=e9626f9767e6e22ece9d765f34ba01c5\nSpeaker Huadong Xiong\nBio I am a first-year Ph.D student in the CNS program, the department of psychology at the University of Arizona, directed by Dr. Robert Wilson. I build models to understand behaviors and I study how computation could be implemented in neural networks. Following the release of GPT-4, my research interest has partially shifted towards understanding the emergence of intelligence within large language models.\nAbstract The exploration-exploitation trade-off, balancing the acquisition of new information with the utilization of known resources, is a fundamental dilemma faced by all adaptive intelligence.","title":"Huadong Xiong | Neural network modeling reveals diverse human exploration behaviors via state space analysis"},{"content":"MindRL is an academic commuity for researchers in the field of reinforcement learning. We co-founded this community with the hope of providing a platform for researchers to communicate and collaborate. We welcome peers from fields such as psychology, cognitive neuroscience, artificial intelligence, and other related disciplines such as mathematics, management and economics to build a more diverse and inclusive platform.\nWe have various activities such as:\nResearch Recap: researchers share their original research in RL. Journal Jam: community members interpret and report on journal articles in RL. Book Breakdown: community members read classic and cutting-edge books together. Tutorial Talks: community members share tutorials and practical experiences in RL. Tool Time: community members share the use and development of tools in RL. Who are we At the heart of the MindRL Hub Community lies the collective vision of four passionate friends, united by a common purpose to foster innovation, knowledge sharing, and collaboration in the fields of psychology, neuroscience and reinforcement learning.\nOur organizing committee is composed of Zeming Fang, Huaiyu Liu, Yanan Liu, and Hanbo Xie (in order of surname), each bringing a unique blend of expertise, experience, and cultural perspectives to the table. Hailing from diverse corners of the world, based on China, the UK, Canada, and the United States, we proudly represent a global network of minds dedicated to advancing the frontiers of reinforcement learning.\nWelcome to a community where geographical boundaries blur, and ideas flow freely across borders. How to join us If you want to join the community or participate in an event, please feel free to contact us via email (rldmjc2023@gmail.com).\n","permalink":"https://RLDMJC.github.io/about/","summary":"about","title":"What is MindRL"}]